# DataEngineeringZoomCamp


---
# [Première Semaine - First Week](https://github.com/le-oasis/DataEngineeringZoomCamp/tree/main/Premi%C3%A8re%20Semaine%20-%20First%20Week):


- During the first week, we established the foundation of our data pipeline project, focusing on Docker setup, data ingestion, and initial exploration. 
- Key tasks included downloading NY Taxi data, creating a Docker environment, setting up PostgreSQL for data storage, and beginning data exploration with Jupyter Notebooks. 
- This week was critical in laying the groundwork for our scalable data pipeline.


---
# [Deuxième Semaine - Second Week](https://github.com/le-oasis/DataEngineeringZoomCamp/tree/main/02-%20Deuxi%C3%A8me%20Semaine%20-%20Second%20Week):


**Overview**
- The second week advances our journey into data engineering by incorporating Docker for containerization, exploring sophisticated data transformation techniques, and leveraging multi-platform data storage solutions. 
- A significant highlight of this week is the introduction of Mage, an open-source orchestration tool designed to enhance data workflow efficiency with principles of flow state, feedback loops, and reduced cognitive load. 
- By integrating Mage, we aim to iterate quickly on pipelines, embody software engineering best practices in our data workflows, and achieve seamless data integration across various platforms. Utilizing the New York Yellow Taxi cab dataset, we focus on executing comprehensive data operations, including extraction, transformation, and loading, facilitated by the unique capabilities of Mage within a Docker environment.

**Objectives**
- Enhanced Containerization with Docker: Continue leveraging Docker to streamline the data processing services, setting a robust foundation for Mage's integration.

- Advanced Data Transformation: Adopt Mage alongside tools like pandas and Apache Arrow to perform data cleaning and transformation. Mage's blocks, written in Python, SQL, or R, offer atomic units for executing these transformations, supporting conditions, dynamic operations, and event-based triggers for comprehensive data engineering tasks.

- Orchestration with Mage: Implement Mage to orchestrate complex data workflows, utilizing its projects, pipelines, and blocks framework for efficient data operations management. Mage's ability to handle multi-user environments, templating, and data integration elevates our pipeline's functionality, enabling us to pass objects seamlessly between different stages and tools.

- Multi-Platform Data Storage Integration: Extend our data engineering capabilities to include Google Cloud Storage (GCS) and Google Big Query, leveraging Mage for orchestrating data flows into these platforms. This objective underscores the project's focus on building scalable, robust data storage solutions that are integral to modern data engineering workflows.

